# 一、选择题
## 1.1.矩阵


## 1.2.概率

## 1.3.数据结构
### 1.3.1.十大经典排序算法

![](images/sort.png)

（1）冒泡排序

（2）选择排序

（3）插入排序

（4）希尔排序

（5）归并排序

（6）快速排序

（7）堆排序

（8）计数排序

（9）桶排序

（10）基数排序

### 1.3.2.小根堆、大根堆

### 1.3.3.KMP算法


### 1.3.4.有向无环图
一般做法
~~~bash
第一步：把各个操作数不重复的排成一排 

第二步：标出各个运算符的生效顺序（先后顺序可能会不同，但是只要符合运算法则就不伤大雅）

第三步：按顺序加入运算符，要分层加入。

第四步：从低向上逐层检查同层的运算符是否可以合体。
~~~

例子
$$
((a+b)*(b*(c+d))+(c+d)*e)*((c+d)*e)
$$

![](images/有向无环图.jpeg)

## 1.4.机器学习

### 1.4.1.决策树
（1）决策树是一种预测模型，代表对象属性和对象值之间的映射关系。决策树是一种树形结构，其中：
* 每个内部结点表示为一个属性的测试
* 每个分支表示一个测试输出
* 每个叶节点代表一种类别

（2）决策树核心部分
* 结点和有向边组成
* 结点有内部结点和叶节点两种类型
* 内部结点表示一个特征，叶节点表示一个类

（3）决策树生长流程

* 决策树的总体流程是从根结点开始到叶结点的递归过程，在每个中间结点寻找一个划分属性

（4）决策树停止生长条件

* 停止条件一：当前结点包含的样全属于同一类别
* 停止条件二：样本的属性取值都相同或属性集为空，不能划分
* 停止条件三：当前结点包含样本集合为空，不能再划分

（5）最优属性选择

* 信息熵

$$
Ent(D) = -\Sigma_{k=1}^{|y|}p_{k}log_2^{p_{k}}
$$

* 信息增益

$$
Gain(D, a) = Ent(D) - \Sigma_{v = 1}^{v}\frac{|D^{v}|}{|D|}Ent(D^{v})
$$

* 信息增益率

    因为信息增益会偏向取值较多的特征
$$
Gain_ratio(D, a) = \frac{Gain(D, a)}{IV(a)}
$$

$$
IV(a) = -\Sigma_{v=1}^{V}\frac{|D^{v}|}{|D|}* log_{2}^{\frac{|D^{v}|}{|D|}}
$$

（6）过拟合与剪枝

分支过多会导致过拟合

（7）预剪枝和后剪枝

* 预剪枝

在决策树生长过程中，对每个结点在划分前进行估计，若当前结点划分不能提升决策树范化性能，则停止划分当前结点为叶结点
* 后减枝

先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能的提升，则将该子树替换为叶结点。

（8）预剪枝和后剪枝的特点

时间开销

* 预剪枝：训练时间开销降低，测试时间开销变低
* 后剪枝：训练时间开销增加，测试时间开销变低

过拟合欠拟合风险

* 预剪枝：过拟合风险降低，欠拟合风险增加
* 后剪枝：过拟合风险降低，欠拟合风险基本不变

范化性能

* 后剪枝通常优于预剪枝

### 


# 二、编程题
## 2.1.京东(2025算法开发工程师第四批)

（1）题目一
有一个字符串，需要写一个自动求下一个字符串的程序，下一个字符串的长度保持不变，例如输入aa，输出ab，输入aab，输出aac，如果输入zz,因为没有下一个字符串，输出-1


（2）题目二
现在给定一个数组，有两种操作，操作一：交换连续的两个元素，例如[1, 2]变为[2, 1],操作二：交换连续的三个元素，例如[1, 2, 3]变为[3, 2, 1]。现在对一个数组排序，同时保证尽可能的少用操作一，求最少的操作一的次数。


（3）题目三

现在有一个二行N列的二维数组，需要从（1, 1）到（2, N）， 两个人分为选择下一步（向上，向下，向右）

## 2.2.小红书（2025机器学习&音视频第一批）20240901

（1）题目一

求最长的山峰

如果有一个数组，存在子数组，前面的元素都严格递增到山峰，后面的元素都严格递减，例如[1, 1, 4, 5, 2, 3]中子数组[1, 4, 5, 2]是一个山峰，[1],[1, 2], [1, 2, 3]不是山峰

（2）题目二

求不美观度最小

有一个物品数组和一个是否可以移动的数组，物品数组有两个类别，一个类别1,一个类别2,一个是否可以移动的数组，0表示不能移动，1表示可以移动，定义如果两个相邻的物品类别不同，则不美观，如何移动物品使得不美观度最小